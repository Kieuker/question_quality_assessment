{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4761b519-2830-4fc1-9c68-5557bbafe02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe780422-531c-4142-9f10-43fb74451ba5",
   "metadata": {},
   "source": [
    "# Code01 Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4079bd1-0434-494b-b7b5-c608300ab5f5",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8147c9-ccb0-4bfb-93b9-7c3ac1f4a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function (code from https://competitions.codalab.org/forums/22145/4564/)\n",
    "def evaluate(truth, submission):\n",
    "    # extract ranking\n",
    "    left = list(truth.left)\n",
    "    right = list(truth.right)\n",
    "#     if len(left) != len(right):\n",
    "#     message = 'left and right lengths are not the same'\n",
    "#     sys.exit(message)\n",
    "\n",
    "    submission_left = []\n",
    "    submission_right = []\n",
    "    submission_preference = []\n",
    "    for idx in range(len(left)):\n",
    "        submission_left.append(left[idx])\n",
    "        submission_right.append(right[idx])\n",
    "        ranking_left = submission[submission.QuestionId==left[idx]].ranking.values[0]\n",
    "        ranking_right = submission[submission.QuestionId==right[idx]].ranking.values[0]\n",
    "        preference = 1 if ranking_left < ranking_right else 2\n",
    "        submission_preference.append(preference)\n",
    "    # print(submission_preference)\n",
    "    return submission_preference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79068972-625b-478d-861a-37136746da5d",
   "metadata": {},
   "source": [
    "### Get Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52621533-8102-4b3c-a359-cebc6cefd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "data = pd.read_csv('data/train_data/train_task_3_4.csv')\n",
    "eval_vali = pd.read_csv('data/test_data/quality_response_remapped_public.csv')\n",
    "eval_test = pd.read_csv('data/test_data/quality_response_remapped_private.csv')\n",
    "\n",
    "# submission template\n",
    "template = pd.read_csv('submission/template.csv')\n",
    "\n",
    "# metadatas\n",
    "student_metadata = pd.read_csv('data/metadata/student_metadata_task_3_4.csv')\n",
    "subject_metadata = pd.read_csv('data/metadata/subject_metadata.csv')\n",
    "answer_metadata = pd.read_csv('data/metadata/answer_metadata_task_3_4.csv')\n",
    "question_metadata = pd.read_csv('data/metadata/question_metadata_task_3_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91055387-b900-465f-98eb-d08cbe419818",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41a33ae-a65a-401a-859b-cfa60e1f08f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ranking</th>\n",
       "      <th>SubId</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>CRRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.385214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.808757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>0.401408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.566528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>0.617124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     QuestionId  ranking SubId  CorrectAnswer   CRRatio\n",
       "0             0      NaN    32              1  0.443457\n",
       "1             1      NaN    32              3  0.571429\n",
       "2             2      NaN    32              2  0.385214\n",
       "3             3      NaN    32              2  0.808757\n",
       "4             4      NaN    71              3  0.401408\n",
       "..          ...      ...   ...            ...       ...\n",
       "943         943      NaN    32              4  0.566528\n",
       "944         944      NaN    32              4  0.142857\n",
       "945         945      NaN    32              1  0.422336\n",
       "946         946      NaN    32              2  0.459459\n",
       "947         947      NaN    71              2  0.617124\n",
       "\n",
       "[948 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Subject Grouping - SubId\n",
    "QMD = question_metadata.copy()\n",
    "QMD['SubId'] = QMD.SubjectId.apply(lambda x: x[1:-2].split(', ')[1])\n",
    "QMD.drop(columns=['SubjectId'], inplace=True)\n",
    "\n",
    "# 2. Position of Correct Answer - CorrectAnswer\n",
    "DT = data.copy()\n",
    "DT.drop(columns=['UserId', 'AnswerId','IsCorrect', 'AnswerValue'], inplace=True)\n",
    "DT.drop_duplicates(['QuestionId'], inplace=True, ignore_index=True)\n",
    "\n",
    "# 3. Ratio of Correct Resopnse - CRRatio\n",
    "DT2 = data.copy()\n",
    "DT2.drop(columns=['UserId', 'AnswerId', 'CorrectAnswer', 'AnswerValue'], inplace=True)\n",
    "CRR = DT2.groupby('QuestionId').mean().rename(columns={'IsCorrect':'CRRatio'})\n",
    "\n",
    "# merge to Submission Template \n",
    "mydata = pd.read_csv('submission/template.csv')\n",
    "mydata = pd.merge(left = mydata, right = QMD, how = 'inner', on = 'QuestionId')\n",
    "mydata = pd.merge(mydata, DT, 'inner', 'QuestionId')\n",
    "mydata = pd.merge(mydata, CRR, 'inner', 'QuestionId')\n",
    "\n",
    "display(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7bfdf-ff49-463f-8913-88620d58b281",
   "metadata": {},
   "source": [
    "### Preperation for Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b96dc49-8d62-4ced-923a-1ecd6ddf433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get every quesion ids used in validation set\n",
    "qids_of_vali = eval_vali.left.tolist() + eval_vali.right.tolist()\n",
    "qids_of_vali.sort()\n",
    "\n",
    "# assign random ranking to every questions\n",
    "np.random.seed(20182453)\n",
    "mydata.ranking = np.random.rand(len(mydata))\n",
    "\n",
    "# set the sole decision(Final) from five evaluator decisions\n",
    "eVali = eval_vali.copy()\n",
    "eTest = eval_test.copy()\n",
    "eVali['Final'] = eVali.filter(regex='^T', axis = 1).mean(axis=1).apply(lambda x: 2 if x > 1.5 else 1)\n",
    "eTest['Final'] = eTest.filter(regex='^T', axis = 1).mean(axis=1).apply(lambda x: 2 if x > 1.5 else 1)\n",
    "\n",
    "# swap ranking values to based on Final decision\n",
    "for row in eVali.itertuples():\n",
    "    if row.Final == 1:\n",
    "        if mydata[mydata.QuestionId == row.left].ranking.values[0] < mydata[mydata.QuestionId == row.right].ranking.values[0]:\n",
    "            tmp = mydata[mydata.QuestionId == row.left].ranking.values[0]\n",
    "            mydata[mydata.QuestionId == row.left].ranking.values[0]= mydata[mydata.QuestionId == row.right].ranking.values[0]\n",
    "            mydata[mydata.QuestionId == row.right].ranking.values[0]= tmp\n",
    "    elif row.Final == 2:\n",
    "        if mydata[mydata.QuestionId == row.left].ranking.values[0]> mydata[mydata.QuestionId == row.right].ranking.values[0]:\n",
    "            tmp = mydata[mydata.QuestionId == row.left].ranking.values[0]\n",
    "            mydata[mydata.QuestionId == row.left].ranking.values[0]= mydata[mydata.QuestionId == row.right].ranking.values[0]\n",
    "            mydata[mydata.QuestionId == row.right].ranking.values[0]= tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f8355-1935-4cae-aebf-bb9e9d87dc0d",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d4c9a7-8743-4726-9d10-7d7c0c23afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate mydata(stanard - if question is in validation set)\n",
    "mydata_in_vali = mydata[mydata.QuestionId.isin(qids_of_vali)].copy()\n",
    "mydata_not_vali = mydata[~mydata.QuestionId.isin(qids_of_vali)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78a4f65-4976-4d1c-a2cf-f866fc51e6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.70814095]), array([[-0.002403  ,  0.02228532, -0.43510357]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit linear regression model(in validation set group)\n",
    "y = mydata_in_vali[['ranking']]\n",
    "X = mydata_in_vali[['SubId', 'CorrectAnswer', 'CRRatio']]\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b635624-c595-44f6-a3a8-673cceb95f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict ranking by fit model to non-validation data\n",
    "X2 = mydata_not_vali[['SubId', 'CorrectAnswer', 'CRRatio']]\n",
    "mydata_not_vali['ranking'] = lin_reg.predict(X2)\n",
    "\n",
    "mydata.update(mydata_not_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbecce2e-890d-46c8-a7cf-c8a66b2209fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export result\n",
    "mydata[['QuestionId', 'ranking']].to_csv('submission/Result01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f611764-f630-4810-8205-b7d5f5618de6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ca7cae-9527-4cc0-ae4c-c4868e9f32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimateV = evaluate(eval_test, mydata)\n",
    "trueV = eTest['Final'].tolist()\n",
    "\n",
    "ev = np.array(estimateV)\n",
    "tv = np.array(trueV)\n",
    "\n",
    "samev = (ev == tv)\n",
    "samev.sum() / samev.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
